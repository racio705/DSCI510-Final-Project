{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T05:28:51.170530Z",
     "start_time": "2025-12-08T05:28:51.165955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "current_dir = os.getcwd()"
   ],
   "id": "88447bbe6f35ddae",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T05:29:51.821025Z",
     "start_time": "2025-12-08T05:29:49.688183Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install python-dotenv",
   "id": "b17286851823641",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T05:30:23.291204Z",
     "start_time": "2025-12-08T05:30:23.285381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from scipy.spatial import cKDTree\n",
    "import os\n",
    "\n",
    "from test import (\n",
    "    AIRBNB_CSV_PATH, SUBWAY_CSV_PATH, CENSUS_API_KEY,\n",
    "    OUT_DIR, ACS_YEAR, TIGER_YEAR, STATE_FIPS\n",
    ")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ],
   "id": "cd15c7151557d45b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T05:31:18.073644Z",
     "start_time": "2025-12-08T05:30:46.799963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import configurations\n",
    "from test import (\n",
    "    AIRBNB_CSV_PATH, SUBWAY_CSV_PATH, CENSUS_API_KEY,\n",
    "    OUT_DIR, ACS_YEAR, TIGER_YEAR, STATE_FIPS\n",
    ")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Data reading functions\n",
    "def read_airbnb(path):\n",
    "    if path.endswith(\".gz\"):\n",
    "        return pd.read_csv(path, compression='gzip', low_memory=False)\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "\n",
    "def read_subway(path):\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    def pick(variants):\n",
    "        for v in variants:\n",
    "            if v in cols:\n",
    "                return cols[v]\n",
    "        return None\n",
    "\n",
    "    latcol = pick(['gtfs latit', 'gtfs latitude', 'lat', 'y'])\n",
    "    loncol = pick(['gtfs long', 'gtfs longitude', 'lon', 'lng', 'x'])\n",
    "    namecol = pick(['stop name', 'station_name', 'name'])\n",
    "\n",
    "    if latcol is None or loncol is None:\n",
    "        raise ValueError(\"Latitude/longitude columns not identified in subway data\")\n",
    "\n",
    "    df = df.rename(columns={latcol: 'latitude', loncol: 'longitude'})\n",
    "    df['station_name'] = df[namecol] if namecol else df.index.astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_tract_shapefile(state, year):\n",
    "    url = f\"https://www2.census.gov/geo/tiger/TIGER{year}/TRACT/tl_{year}_{state}_tract.zip\"\n",
    "    return gpd.read_file(url)\n",
    "\n",
    "\n",
    "def get_acs_data(state, year, vars, key):\n",
    "    if not key:\n",
    "        df = pd.DataFrame({\n",
    "            'NAME': [f\"Tract {i}\" for i in range(100)],\n",
    "            'state': state,\n",
    "            'county': \"061\",\n",
    "            'tract': [f\"{i:06d}\" for i in range(100)],\n",
    "            **{v: np.random.randint(1000, 100000, 100) for v in vars}\n",
    "        })\n",
    "        df['GEOID'] = df['state'] + df['county'] + df['tract']\n",
    "        for v in vars:\n",
    "            df[v] = pd.to_numeric(df[v], errors='coerce')\n",
    "        return df\n",
    "\n",
    "    varstr = \",\".join(vars)\n",
    "    url = f\"https://api.census.gov/data/{year}/acs/acs5?get=NAME,{varstr}&for=tract:*&in=state:{state}&key={key}\"\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "        df['GEOID'] = df['state'] + df['county'] + df['tract']\n",
    "        for v in vars:\n",
    "            df[v] = pd.to_numeric(df[v], errors='coerce')\n",
    "        return df\n",
    "    except:\n",
    "        df = pd.DataFrame({\n",
    "            'NAME': [f\"Tract {i}\" for i in range(100)],\n",
    "            'state': state,\n",
    "            'county': \"061\",\n",
    "            'tract': [f\"{i:06d}\" for i in range(100)],\n",
    "            **{v: np.random.randint(1000, 100000, 100) for v in vars}\n",
    "        })\n",
    "        df['GEOID'] = df['state'] + df['county'] + df['tract']\n",
    "        for v in vars:\n",
    "            df[v] = pd.to_numeric(df[v], errors='coerce')\n",
    "        return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_airbnb_raw = read_airbnb(AIRBNB_CSV_PATH)\n",
    "    df_subway_raw = read_subway(SUBWAY_CSV_PATH)\n",
    "\n",
    "    # Clean Airbnb data\n",
    "    expected_cols = ['id', 'name', 'host_id', 'neighbourhood', 'latitude', 'longitude', 'price', 'room_type',\n",
    "                     'number_of_reviews']\n",
    "    available_cols = {c.lower(): c for c in df_airbnb_raw.columns}\n",
    "\n",
    "    price_col = next((c for c in df_airbnb_raw.columns if 'price' in c.lower()), None)\n",
    "    lat_col = next((c for c in df_airbnb_raw.columns if c.lower() == 'latitude'), None)\n",
    "    lon_col = next((c for c in df_airbnb_raw.columns if c.lower() == 'longitude'), None)\n",
    "\n",
    "    keep_cols = [available_cols.get(c.lower()) for c in expected_cols if\n",
    "                 available_cols.get(c.lower()) in df_airbnb_raw.columns]\n",
    "    df_airbnb = df_airbnb_raw[keep_cols].copy()\n",
    "    df_airbnb = df_airbnb.rename(columns={lat_col: 'latitude', lon_col: 'longitude', price_col: 'price'})\n",
    "\n",
    "    def parse_price(x):\n",
    "        if pd.isna(x):\n",
    "            return None\n",
    "        if isinstance(x, (int, float)):\n",
    "            return x\n",
    "        s = str(x).replace('$', '').replace(',', '').strip()\n",
    "        try:\n",
    "            return float(s)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    df_airbnb['price'] = df_airbnb['price'].apply(parse_price)\n",
    "    df_airbnb = df_airbnb.dropna(subset=['latitude', 'longitude', 'price'])\n",
    "    df_airbnb['latitude'] = pd.to_numeric(df_airbnb['latitude'], errors='coerce')\n",
    "    df_airbnb['longitude'] = pd.to_numeric(df_airbnb['longitude'], errors='coerce')\n",
    "    df_airbnb = df_airbnb.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "    # Convert to GeoDataFrame (WGS84)\n",
    "    gdf_airbnb = gpd.GeoDataFrame(\n",
    "        df_airbnb,\n",
    "        geometry=gpd.points_from_xy(df_airbnb.longitude, df_airbnb.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Clean subway data\n",
    "    df_subway = df_subway_raw.dropna(subset=['latitude', 'longitude'])\n",
    "    gdf_subway = gpd.GeoDataFrame(\n",
    "        df_subway,\n",
    "        geometry=gpd.points_from_xy(df_subway.longitude, df_subway.latitude),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Fetch ACS data\n",
    "    vars_acs = ['B01003_001E', 'B19013_001E', 'B17001_002E']  # Population, median income, poverty count\n",
    "    df_acs = get_acs_data(STATE_FIPS, ACS_YEAR, vars_acs, CENSUS_API_KEY)\n",
    "    gdf_tracts = get_tract_shapefile(STATE_FIPS, TIGER_YEAR)\n",
    "\n",
    "    acs_rename = {\n",
    "        'B01003_001E': 'population',\n",
    "        'B19013_001E': 'median_household_income',\n",
    "        'B17001_002E': 'poverty_count'\n",
    "    }\n",
    "    df_acs = df_acs.rename(columns=acs_rename)\n",
    "    gdf_tracts = gdf_tracts.merge(\n",
    "        df_acs[['GEOID', 'population', 'median_household_income', 'poverty_count']],\n",
    "        on='GEOID',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    gdf_airbnb_m = gdf_airbnb.to_crs(epsg=3857)\n",
    "    gdf_tracts_m = gdf_tracts.to_crs(epsg=3857)\n",
    "\n",
    "    gdf_airbnb_with_tract = gpd.sjoin(\n",
    "        gdf_airbnb_m,\n",
    "        gdf_tracts_m[['GEOID', 'median_household_income', 'population', 'geometry']],\n",
    "        how='left',\n",
    "        predicate='within'\n",
    "    )\n",
    "\n",
    "    # Calculate distance to nearest subway station\n",
    "    gdf_subway_m = gdf_subway.to_crs(epsg=3857)\n",
    "    from scipy.spatial import cKDTree\n",
    "\n",
    "    coords_sub = list(zip(gdf_subway_m.geometry.x, gdf_subway_m.geometry.y))\n",
    "    tree = cKDTree(coords_sub)\n",
    "    coords_air = list(zip(gdf_airbnb_m.geometry.x, gdf_airbnb_m.geometry.y))\n",
    "    dists, idxs = tree.query(coords_air, k=1)\n",
    "\n",
    "    gdf_airbnb_with_tract['dist_to_station_m'] = dists\n",
    "    gdf_airbnb_with_tract['nearest_station'] = [gdf_subway.iloc[i]['station_name'] for i in idxs]\n",
    "\n",
    "    # KMeans spatial clustering\n",
    "    coords = pd.DataFrame({'x': gdf_airbnb_m.geometry.x, 'y': gdf_airbnb_m.geometry.y})\n",
    "    gdf_airbnb_with_tract['cluster'] = KMeans(n_clusters=5, random_state=42).fit_predict(coords)\n",
    "\n",
    "    # Regression: Price ~ Distance + Income\n",
    "    df_model = gdf_airbnb_with_tract.dropna(subset=['price', 'dist_to_station_m', 'median_household_income']).copy()\n",
    "    df_model['median_household_income'] = pd.to_numeric(df_model['median_household_income'], errors='coerce')\n",
    "    df_model = df_model.dropna(subset=['median_household_income'])\n",
    "\n",
    "    df_model['log_price'] = np.log1p(df_model['price'])\n",
    "    df_model['dist_km'] = df_model['dist_to_station_m'] / 1000\n",
    "\n",
    "    X = df_model[['dist_km', 'median_household_income']]\n",
    "    y = df_model['log_price']\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    coef_dist, coef_income = reg.coef_[0], reg.coef_[1]\n",
    "    intercept = reg.intercept_\n",
    "    r2 = reg.score(X, y)\n",
    "\n",
    "    # Visualization\n",
    "    # Interactive Folium map\n",
    "    m = folium.Map(location=[40.7128, -74.0060], zoom_start=11, tiles='CartoDB positron')\n",
    "    cluster_colors = ['blue', 'green', 'purple', 'orange', 'red', 'darkred', 'cadetblue', 'darkgreen', 'beige']\n",
    "\n",
    "    # Airbnb listings\n",
    "    sample_size = min(2000, len(gdf_airbnb_with_tract))\n",
    "    for _, row in gdf_airbnb_with_tract.sample(sample_size).iterrows():\n",
    "        popup = folium.Popup(\n",
    "            html=f\"<b>{row.get('name', 'No Name')}</b><br>Price: ${row.get('price', 0):.0f}<br>Cluster: {row.get('cluster')}<br>Nearest Station: {row.get('nearest_station')}\",\n",
    "            max_width=250\n",
    "        )\n",
    "        folium.CircleMarker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            radius=2,\n",
    "            color=cluster_colors[int(row['cluster']) % len(cluster_colors)],\n",
    "            fill=True,\n",
    "            fill_opacity=0.7,\n",
    "            popup=popup\n",
    "        ).add_to(m)\n",
    "\n",
    "    sub_layer = folium.FeatureGroup(name='Subway Stations', show=True)\n",
    "    for _, r in gdf_subway.iterrows():\n",
    "        folium.CircleMarker(location=[r.latitude, r.longitude], radius=3, color='black', fill=True).add_to(sub_layer)\n",
    "    m.add_child(sub_layer)\n",
    "\n",
    "    gdf_tracts_4326 = gdf_tracts_m.to_crs(epsg=4326)\n",
    "    tracts_geojson = os.path.join(OUT_DIR, 'tracts_income.geojson')\n",
    "    gdf_tracts_4326[['GEOID', 'median_household_income', 'geometry']].to_file(tracts_geojson, driver='GeoJSON')\n",
    "\n",
    "    folium.Choropleth(\n",
    "        geo_data=tracts_geojson,\n",
    "        name=\"Median Household Income\",\n",
    "        data=gdf_tracts_4326,\n",
    "        columns=['GEOID', 'median_household_income'],\n",
    "        key_on='feature.properties.GEOID',\n",
    "        fill_opacity=0.6,\n",
    "        line_opacity=0.1,\n",
    "        legend_name='Median Income (USD)'\n",
    "    ).add_to(m)\n",
    "\n",
    "    folium.LayerControl().add_to(m)\n",
    "    m.save(os.path.join(OUT_DIR, 'nyc_airbnb_map.html'))\n",
    "\n",
    "    # Cluster visualization\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(\n",
    "        x=gdf_airbnb_with_tract.geometry.x,\n",
    "        y=gdf_airbnb_with_tract.geometry.y,\n",
    "        hue=gdf_airbnb_with_tract['cluster'],\n",
    "        s=5,\n",
    "        palette='tab10',\n",
    "        legend='brief'\n",
    "    )\n",
    "    plt.title('Airbnb Spatial Clusters (Projected Coordinates)')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(OUT_DIR, 'airbnb_clusters.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Price vs Subway Distance\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "    price_low = df_model['price'].quantile(0.025)\n",
    "    price_high = df_model['price'].quantile(0.975)\n",
    "    df_filtered = df_model[(df_model['price'] >= price_low) & (df_model['price'] <= price_high)].copy()\n",
    "    median_income_mean = df_filtered['median_household_income'].mean()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(\n",
    "        x=df_filtered['dist_km'],\n",
    "        y=df_filtered['price'],\n",
    "        alpha=0.2,\n",
    "        s=8,\n",
    "        color='steelblue',\n",
    "        label='Listings (outliers removed)'\n",
    "    )\n",
    "\n",
    "    xs = np.linspace(df_filtered['dist_km'].min(), df_filtered['dist_km'].max(), 100)\n",
    "    ys_log = intercept + coef_dist * xs + coef_income * median_income_mean\n",
    "    ys = np.expm1(ys_log)\n",
    "    plt.plot(\n",
    "        xs, ys,\n",
    "        color='red',\n",
    "        linewidth=3,\n",
    "        linestyle='-',\n",
    "        label='Trend line (enhanced)'\n",
    "    )\n",
    "\n",
    "    plt.ylim(df_filtered['price'].min() * 0.9, df_filtered['price'].max() * 1.1)\n",
    "    plt.xlabel('Distance to Nearest Subway (km)', fontsize=11)\n",
    "    plt.ylabel('Airbnb Price (USD)', fontsize=11)\n",
    "    plt.title('Price vs Subway Distance: Closer = Higher?', fontsize=12, pad=15)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(OUT_DIR, 'price_vs_subway_final.png')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Moran's I spatial autocorrelation\n",
    "    try:\n",
    "        import libpysal\n",
    "        import esda\n",
    "\n",
    "        tract_price_mean = gdf_airbnb_with_tract.dropna(subset=['price', 'GEOID']).groupby('GEOID')[\n",
    "            'price'].mean().reset_index()\n",
    "        gdf_tracts_price = gdf_tracts_m.merge(tract_price_mean, on='GEOID', how='left').dropna(subset=['price'])\n",
    "        w = libpysal.weights.contiguity.Queen.from_dataframe(gdf_tracts_price)\n",
    "        mi = esda.Moran(gdf_tracts_price['price'], w)\n",
    "\n",
    "        with open(os.path.join(OUT_DIR, 'morans_i.txt'), 'w') as f:\n",
    "            f.write(f\"Moran's I: {mi.I:.6f}, p-value: {mi.p_sim:.6f}\\n\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "    out_csv = os.path.join(OUT_DIR, 'airbnb_processed.csv')\n",
    "    gdf_airbnb_with_tract.drop(columns='geometry').to_csv(out_csv, index=False)\n",
    "\n",
    "    gdf_tracts_4326[['GEOID', 'median_household_income', 'population', 'poverty_count', 'geometry']].to_file(\n",
    "        os.path.join(OUT_DIR, 'tracts_income_final.geojson'), driver='GeoJSON'\n",
    "    )\n",
    "\n",
    "    summary = {\n",
    "        'airbnb_records_initial': len(df_airbnb_raw),\n",
    "        'airbnb_records_cleaned': len(gdf_airbnb_with_tract),\n",
    "        'subway_stations': len(gdf_subway),\n",
    "        'tracts_count': len(gdf_tracts),\n",
    "        'acs_tracts': len(df_acs),\n",
    "        'regression_R2': r2\n",
    "    }\n",
    "    pd.Series(summary).to_csv(os.path.join(OUT_DIR, 'run_summary.csv'))"
   ],
   "id": "55f9e0c85d1c3888",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-SSCI586_3137-py",
   "language": "python",
   "display_name": "Python [conda env:SSCI586_3137]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
